{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charged-opening",
   "metadata": {},
   "source": [
    "# <b><font color=\"#FF6633\">VGG</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-glossary",
   "metadata": {},
   "source": [
    "## 包导入与参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weekly-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载tensorflow模型\n",
    "import numpy as np\n",
    "import os\n",
    "# Uncomment the line below to make GPU unavaliable\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "from tensorflow.keras.layers import Dense,Dropout, Input, concatenate,Flatten\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-formula",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "1. 采用**vgg16**进行分类，使用在imageNet上进行预训练的模型进行迁移学习（当然我们的任务和和物体分类差别很大，所有预训练的模型在这里意义不是很大）  \n",
    "2. 池化选择**平均池化**：因为我们想要的是全局特征，平均池化有利于滤除细微的扰动【但我不确定max_pool是否会更好】   \n",
    "3. 优化方式为**sgd**,随机性更强的sgd更有利于跳过局部最优，对于我们的任务来说，当然是有必要的  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nearby-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义宏参数\n",
    "PICS_WIDTH,PICS_HEIGHT = 512,512\n",
    "MODEL_LOSS = 'categorical_crossentropy'\n",
    "MODEL_METRIC = 'categorical_accuracy'\n",
    "NUM_CATEGS = 10\n",
    "\n",
    "def InitialiazeModel(head_only,weights,model_name,lr=0.001):\n",
    "    \"\"\"\n",
    "    head_only:选择是否只训练顶端（即自定义的全连接层）\n",
    "    weights:选择是否从外部导入权重\n",
    "    model:模型名称\n",
    "    lr:学习率：默认为0.001\n",
    "    \"\"\"\n",
    "    if model_name == 'VGG19':\n",
    "        from tensorflow.keras.applications.vgg19 import VGG19\n",
    "        base_model = VGG19(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    # ================================ 该实验选择的分类器 ============================================ #\n",
    "    elif model_name == 'VGG16':\n",
    "        from tensorflow.keras.applications.vgg16 import VGG16\n",
    "        base_model = VGG16(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "        \n",
    "    # ============================================================================================== #\n",
    "    elif model_name == 'MobileNet':\n",
    "        from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "        base_model = MobileNet(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'ResNet50':\n",
    "        from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'Xception':\n",
    "        from tensorflow.keras.applications.xception import Xception\n",
    "        base_model = Xception(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'InceptionV3':\n",
    "        from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "        base_model = InceptionV3(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'InceptionResNetV2':\n",
    "        from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "        base_model = InceptionResNetV2(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'NASNetLarge':\n",
    "        from tensorflow.keras.applications.nasnet import NASNetLarge\n",
    "        base_model = NASNetLarge(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'NASNetMobile':\n",
    "        from tensorflow.keras.applications.nasnet import NASNetMobile\n",
    "        base_model = NASNetMobile(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    else:\n",
    "        raise ValueError('Network name is undefined')\n",
    "    # 是否训练头部    \n",
    "    if head_only:\n",
    "        for lay in base_model.layers:\n",
    "            lay.trainable = False\n",
    "            \n",
    "    for i,lay in enumerate(base_model.layers):\n",
    "            # print(i,lay)\n",
    "            if i <= 14:\n",
    "                lay.trainable = False\n",
    "\n",
    "    # ======================= 全连接层 ======================================\n",
    "    flat1 = Flatten()(base_model.layers[-1].output)\n",
    "    # 第一层\n",
    "    class1 = Dense(256, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    dropout1 = Dropout(0.2)(class1)\n",
    "      # 第二层\n",
    "    class2 = Dense(128, activation='relu', kernel_initializer='he_uniform')(dropout1)\n",
    "    dropout2 = Dropout(0.2)(class2)\n",
    "    # 输出层\n",
    "    output = Dense(NUM_CATEGS, activation='softmax')(dropout2)\n",
    "    # define new model\n",
    "    model = Model(inputs=base_model.inputs, outputs=output)\n",
    "    \n",
    "    # print(model.summary())\n",
    "    # 如果存在已有权重则加载已有权重\n",
    "    if weights != '':\n",
    "        model.load_weights(weights)\n",
    "    # ========================= 优化器 =======================================\n",
    "#     MODEL_OPTIMIZER = optimizers.Adam(lr=0.001)\n",
    "    MODEL_OPTIMIZER = optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    # 编译模型\n",
    "    model.compile(loss=MODEL_LOSS, optimizer=MODEL_OPTIMIZER, metrics=[MODEL_METRIC])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "InitialiazeModel(head_only=True,weights='',model_name='VGG16',lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-enclosure",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "定义训练用变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technological-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "# 模型名\n",
    "model_name = \"VGG16\"\n",
    "train_path = \"./datasets/Train\"\n",
    "val_path = \"./datasets/Val_main\"\n",
    "BATCH_SIZE = 20\n",
    "train_sample_num = 9054\n",
    "val_sample_num = 1555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-grade",
   "metadata": {},
   "source": [
    "### 数据生成器\n",
    "生成类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44e4dbd-af05-49ce-b8c7-d20283ef9783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple_iPhone6Plus', 'Canon_PowerShotA640', 'Huawei_P9', 'Lenovo_P70A', 'Microsoft_Lumia640LTE', 'Nikon_D70s', 'OnePlus_A3003', 'Samsung_GalaxyS5', 'Sony_DSC-W170', 'Xiaomi_RedmiNote3']\n"
     ]
    }
   ],
   "source": [
    "category = os.listdir(\"./datasets/Train\")\n",
    "if '.ipynb_checkpoints' in category:\n",
    "    category.remove('.ipynb_checkpoints')\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-scheduling",
   "metadata": {},
   "source": [
    "很麻烦的一件事是，初始的vgg16权重是在ImageNet上训练的，需要通过preprocess_input函数处理，而问题是keras的生成器函数ImageDataGenerator  \n",
    "没有提供能进行自定义预处理的接口。一个聪明的方法是**自定义一个生成器封装ImageDataGenerator，对ImageDataGenerator生成的图像进行处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norman-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_gen(directory,classes):\n",
    "    \"\"\"\n",
    "    生成器，对ImageDataGenerator的输出进行处理\n",
    "    \"\"\"\n",
    "    data_gen = ImageDataGenerator()\n",
    "    train_it = data_gen.flow_from_directory(directory=directory,target_size=(512,512),\n",
    "                                           classes=category,class_mode= \"categorical\",\n",
    "                                            batch_size=BATCH_SIZE)\n",
    "    while True:\n",
    "        X,y = next(train_it)\n",
    "        X = preprocess_input(X)\n",
    "        yield(X,y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-quantity",
   "metadata": {},
   "source": [
    "--- \n",
    "从头开始（毕竟我们数据大）{事实证明这个效果很好}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau\n",
    "from math import ceil\n",
    "\n",
    "model_name = \"VGG16\"\n",
    "train_path = \"./datasets/Train\"\n",
    "val_path = \"./datasets/Val_main\"\n",
    "BATCH_SIZE = 24\n",
    "train_sample_num = 30000\n",
    "val_sample_num = 1555\n",
    "weights = './model_weight/sgd_not_only_head05.hdf5'\n",
    "# weights = ''\n",
    "\n",
    "model = InitialiazeModel(head_only=False,weights=weights,model_name = model_name, lr=0.001)\n",
    "\n",
    "weights_path_name = \"./model_weight/sgd_not_only_head{epoch:02d}.hdf5\" \n",
    "callbacks = [ModelCheckpoint(weights_path_name, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=3, verbose=0.01),\n",
    "             TensorBoard(log_dir='train_log',update_freq=20000),\n",
    "             ReduceLROnPlateau(factor=0.5,\n",
    "                               patience=1, \n",
    "                              min_lr=0.0005)]\n",
    "history1 = model.fit_generator(generator = vgg16_gen(train_path,category),\n",
    "                    validation_data = vgg16_gen(val_path,category),\n",
    "                    epochs = 40,\n",
    "                    steps_per_epoch=ceil(train_sample_num/ BATCH_SIZE),\n",
    "                    validation_steps=ceil(val_sample_num/ BATCH_SIZE),\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffe3dc-5e28-4f5f-b021-1ae2ad51564f",
   "metadata": {},
   "source": [
    "## 评价\n",
    "注： 建议在此重启内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8215ad9e-5f34-4d39-a47a-670177b83b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Vgg16\n",
    "model = Vgg16(head_only=False,weights='./model_weight/sgd_not_only_head06.hdf5')\n",
    "BATCH_SIZE = 24\n",
    "val_sample_num = 1555\n",
    "val_result = evaluate_generator(vgg16_gen(val_path,category), stepsceil(val_sample_num/ BATCH_SIZE))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
