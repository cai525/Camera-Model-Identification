{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d413b3-4a0e-4f7d-ab0d-50105b6659b4",
   "metadata": {},
   "source": [
    "# <b><font color=\"#FF6633\">LBP + Alex</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c150c7d-cf9a-4d53-8225-fafbab2714f2",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fff9704-2ed4-46ac-9dbf-039e7d18428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,ReLU,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "MODEL_LOSS = 'categorical_crossentropy'\n",
    "MODEL_METRIC = 'categorical_accuracy'\n",
    "\n",
    "def InitialiazeModel(lr):\n",
    "    \"\"\"\n",
    "    head_only:选择是否只训练顶端（即自定义的全连接层）\n",
    "    weights:选择是否从外部导入权重\n",
    "    model:模型名称\n",
    "    lr:学习率：默认为0.001\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    in_shape=(512, 512, 1)\n",
    "    model.add(Conv2D(32, (5, 5),kernel_initializer='he_uniform', strides=(3,3),padding='valid', input_shape=in_shape))\n",
    "    model.add(BatchNormalization(momentum=0.9)) # 根据batch_size修改\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((3, 3),strides=1,padding='same'))\n",
    "    # repeat\n",
    "    model.add(Conv2D(32, (5, 5),kernel_initializer='he_uniform', strides=(3,3),padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.9)) # 根据batch_size修改\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((3, 3),strides=1,padding='same'))\n",
    "    # repeat\n",
    "    model.add(Conv2D(32, (5, 5),kernel_initializer='he_uniform', strides=(3,3),padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.9)) # 根据batch_size修改\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((3, 3),strides=1,padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # ========================= 优化器 =======================================\n",
    "    MODEL_OPTIMIZER = optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    # MODEL_OPTIMIZER = optimizers.Adam()\n",
    "    # 编译模型\n",
    "    model.compile(loss=MODEL_LOSS, optimizer=MODEL_OPTIMIZER, metrics=[MODEL_METRIC])\n",
    "    # model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d909220-66fd-476d-a5ea-17956897f8c7",
   "metadata": {},
   "source": [
    "## 目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0fdb5b8-e009-402a-b447-d71ab0308d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple_iPhone6Plus', 'Canon_PowerShotA640', 'Huawei_P9', 'Lenovo_P70A', 'Microsoft_Lumia640LTE', 'Nikon_D70s', 'OnePlus_A3003', 'Samsung_GalaxyS5', 'Sony_DSC-W170', 'Xiaomi_RedmiNote3']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "category = os.listdir(\"datasets\\\\Train\")\n",
    "category.remove('.ipynb_checkpoints')\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e4f90-9686-46fd-8ab1-a37d4bcb75b0",
   "metadata": {},
   "source": [
    "## 生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a5f899-72cf-4fd5-9c16-108766d4ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.feature import local_binary_pattern\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def LBP_gen(directory,classes):\n",
    "    # 包引入\n",
    "    data_gen = ImageDataGenerator()\n",
    "    train_it = data_gen.flow_from_directory(directory=directory,target_size=(256,256),\n",
    "                                           classes=category,class_mode= \"categorical\",\n",
    "                                            batch_size=BATCH_SIZE)\n",
    "    while True:\n",
    "        X,y = next(train_it)\n",
    "        g = rgb_to_grayscale(X)\n",
    "        g = g.numpy() \n",
    "        shape = g.shape\n",
    "        for i in range(shape[0]):\n",
    "            g[i,:256, :256,0] = local_binary_pattern(g[i,:256, :256,0], 8, 1)\n",
    "                \n",
    "        yield(g[:,:256,:256,:],y)   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2a6c1-eaee-4fa5-af53-63bc3b8d6c80",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03570442-d7e0-4f46-9e39-e5789a85eec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\44332\\AppData\\Local\\Temp\\ipykernel_5096\\3323860162.py:20: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 30150 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "  1/938 [..............................] - ETA: 0s - loss: 4.0834 - categorical_accuracy: 0.1562WARNING:tensorflow:From F:\\anaconda\\envs\\tensorflow2.3.1\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "938/938 [==============================] - ETA: 0s - loss: 1.9370 - categorical_accuracy: 0.3330Found 1555 images belonging to 10 classes.\n",
      "938/938 [==============================] - 1446s 2s/step - loss: 1.9370 - categorical_accuracy: 0.3330 - val_loss: 2.9326 - val_categorical_accuracy: 0.1891\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 1428s 2s/step - loss: 1.1198 - categorical_accuracy: 0.6192 - val_loss: 1.5254 - val_categorical_accuracy: 0.4617\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 1413s 2s/step - loss: 0.8997 - categorical_accuracy: 0.6941 - val_loss: 1.2727 - val_categorical_accuracy: 0.5826\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 1412s 2s/step - loss: 0.7874 - categorical_accuracy: 0.7291 - val_loss: 3.3672 - val_categorical_accuracy: 0.3550\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 1417s 2s/step - loss: 0.6043 - categorical_accuracy: 0.7880 - val_loss: 1.1626 - val_categorical_accuracy: 0.6283\n",
      "Epoch 6/100\n",
      " 28/938 [..............................] - ETA: 20:52 - loss: 0.5496 - categorical_accuracy: 0.8218"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau\n",
    "from math import ceil\n",
    "\n",
    "train_path = \"datasets\\\\Train\"\n",
    "val_path = \"datasets\\\\Val_main\"\n",
    "BATCH_SIZE = 32\n",
    "train_sample_num = 30000\n",
    "val_sample_num = 1555\n",
    "\n",
    "# 训练\n",
    "model = InitialiazeModel(lr=0.01)\n",
    "weights_path_name = \"model_weight\\\\LBP\\\\lbp{epoch:02d}.hdf5\" \n",
    "callbacks = [ModelCheckpoint(weights_path_name, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=5, verbose=0.001),\n",
    "             TensorBoard(log_dir='train_log\\\\Alex',update_freq='epoch'),\n",
    "             ReduceLROnPlateau(factor=0.4,\n",
    "                               patience=1, \n",
    "                              min_lr=0.001)]\n",
    "history1 = model.fit_generator(generator = LBP_gen(train_path,category),\n",
    "                    validation_data = LBP_gen(val_path,category),\n",
    "                    epochs = 100,\n",
    "                    steps_per_epoch=ceil(train_sample_num/ BATCH_SIZE),\n",
    "                    validation_steps=ceil(val_sample_num/ BATCH_SIZE),\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152008e-e8c4-4522-b44e-adfb3c8341b4",
   "metadata": {},
   "source": [
    "## 版本二：原汁原味的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3578cc-6aec-4d19-be16-bbcbf334d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,ReLU,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "MODEL_LOSS = 'categorical_crossentropy'\n",
    "MODEL_METRIC = 'categorical_accuracy'\n",
    "\n",
    "def InitialiazeModel(lr):\n",
    "    \"\"\"\n",
    "    head_only:选择是否只训练顶端（即自定义的全连接层）\n",
    "    weights:选择是否从外部导入权重\n",
    "    model:模型名称\n",
    "    lr:学习率：默认为0.001\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    in_shape=(256, 256, 1)\n",
    "    model.add(Conv2D(64, (3, 3),kernel_initializer='he_uniform', strides=(2,2),padding='valid', input_shape=in_shape))\n",
    "    model.add(BatchNormalization(momentum=0.95)) # 根据batch_size修改\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((3, 3),strides=1,padding='same'))\n",
    "    # repeat\n",
    "    model.add(Conv2D(64, (3, 3),kernel_initializer='he_uniform', strides=(2,2),padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.95)) # 根据batch_size修改\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((3, 3),strides=1,padding='same'))\n",
    "    # repeat\n",
    "    model.add(Conv2D(32, (3, 3),kernel_initializer='he_uniform', strides=(2,2),padding='valid'))\n",
    "    model.add(BatchNormalization(momentum=0.95)) # 根据batch_size修改\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling2D((3, 3),strides=1,padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # ========================= 优化器 =======================================\n",
    "    MODEL_OPTIMIZER = optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    # MODEL_OPTIMIZER = optimizers.Adam()\n",
    "    # 编译模型\n",
    "    model.compile(loss=MODEL_LOSS, optimizer=MODEL_OPTIMIZER, metrics=[MODEL_METRIC])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ee009b-b117-475f-b609-7b620368c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 127, 127, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 127, 127, 64)      256       \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 63, 63, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 63, 63, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 31, 31, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 30752)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              31491072  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 31,812,714\n",
      "Trainable params: 31,812,394\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x26d9a1af460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InitialiazeModel(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f533ec-3c1c-4313-a82f-cb6671ff49b5",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8cb642-ed75-4d4e-91cd-2aeb0e592ad8",
   "metadata": {},
   "source": [
    "第一轮将momentum设为0.5，防止开始直接梯度爆炸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607b528-722e-44ed-8252-7e050f30d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\44332\\AppData\\Local\\Temp\\ipykernel_10296\\4108529627.py:20: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 30150 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "  1/469 [..............................] - ETA: 0s - loss: 4.6229 - categorical_accuracy: 0.1094WARNING:tensorflow:From F:\\anaconda\\envs\\tensorflow2.3.1\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/469 [..............................] - ETA: 50s - loss: 23.1511 - categorical_accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0529s vs `on_train_batch_end` time: 0.1640s). Check your callbacks.\n",
      "469/469 [==============================] - ETA: 0s - loss: 2.9027 - categorical_accuracy: 0.2556Found 1555 images belonging to 10 classes.\n",
      "469/469 [==============================] - 470s 1s/step - loss: 2.9027 - categorical_accuracy: 0.2556 - val_loss: 2.1808 - val_categorical_accuracy: 0.2379\n",
      "Epoch 2/100\n",
      " 20/469 [>.............................] - ETA: 6:33 - loss: 1.9606 - categorical_accuracy: 0.3036"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau\n",
    "from math import ceil\n",
    "\n",
    "train_path = \"datasets\\\\Train\"\n",
    "val_path = \"datasets\\\\Val_main\"\n",
    "BATCH_SIZE = 64\n",
    "train_sample_num = 30000\n",
    "val_sample_num = 1555\n",
    "\n",
    "# 训练\n",
    "model = InitialiazeModel(lr=0.02)\n",
    "weights_path_name = \"model_weight\\\\LBP\\\\lbp{epoch:02d}.hdf5\" \n",
    "callbacks = [ModelCheckpoint(weights_path_name, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=5, verbose=0.001),\n",
    "             TensorBoard(log_dir='train_log\\\\Alex',update_freq='epoch'),\n",
    "             ReduceLROnPlateau(factor=0.2,\n",
    "                               patience=2, \n",
    "                              min_lr=0.001)]\n",
    "history1 = model.fit_generator(generator = LBP_gen(train_path,category),\n",
    "                    validation_data = LBP_gen(val_path,category),\n",
    "                    epochs = 100,\n",
    "                    steps_per_epoch=ceil(train_sample_num/ BATCH_SIZE),\n",
    "                    validation_steps=ceil(val_sample_num/ BATCH_SIZE),\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0949d4-c2ec-4bba-a094-3b368138dbcb",
   "metadata": {},
   "source": [
    "第二轮开始设置momentum=0.9,继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc963c11-4671-4e50-9d23-3271da857225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\44332\\AppData\\Local\\Temp\\ipykernel_13960\\1085703981.py:20: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 30150 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "  2/469 [..............................] - ETA: 44s - loss: 1.8546 - categorical_accuracy: 0.4141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0530s vs `on_train_batch_end` time: 0.1360s). Check your callbacks.\n",
      "469/469 [==============================] - ETA: 0s - loss: 1.7648 - categorical_accuracy: 0.3800Found 1555 images belonging to 10 classes.\n",
      "469/469 [==============================] - 477s 1s/step - loss: 1.7648 - categorical_accuracy: 0.3800 - val_loss: 2.1925 - val_categorical_accuracy: 0.3048\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 485s 1s/step - loss: 1.4883 - categorical_accuracy: 0.4789 - val_loss: 2.9381 - val_categorical_accuracy: 0.2244\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 483s 1s/step - loss: 1.3060 - categorical_accuracy: 0.5506 - val_loss: 1.7073 - val_categorical_accuracy: 0.4103\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 471s 1s/step - loss: 1.1491 - categorical_accuracy: 0.6062 - val_loss: 5.4318 - val_categorical_accuracy: 0.2334\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 471s 1s/step - loss: 1.0186 - categorical_accuracy: 0.6505 - val_loss: 5.0052 - val_categorical_accuracy: 0.2958\n",
      "Epoch 6/100\n",
      " 93/469 [====>.........................] - ETA: 5:53 - loss: 0.8633 - categorical_accuracy: 0.7107"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau\n",
    "from math import ceil\n",
    "\n",
    "train_path = \"datasets\\\\Train\"\n",
    "val_path = \"datasets\\\\Val_main\"\n",
    "BATCH_SIZE = 64\n",
    "train_sample_num = 30000\n",
    "val_sample_num = 1555\n",
    "\n",
    "# 训练\n",
    "model = InitialiazeModel(lr=0.02)\n",
    "model.load_weights('model_weight/LBP/lbp01.hdf5')\n",
    "weights_path_name = \"model_weight\\\\LBP\\\\lbp{epoch:02d}+1.hdf5\" \n",
    "callbacks = [ModelCheckpoint(weights_path_name, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=5, verbose=0.001),\n",
    "             ReduceLROnPlateau(factor=0.2,\n",
    "                               patience=2, \n",
    "                              min_lr=0.001)]\n",
    "history1 = model.fit_generator(generator = LBP_gen(train_path,category),\n",
    "                    validation_data = LBP_gen(val_path,category),\n",
    "                    epochs = 100,\n",
    "                    steps_per_epoch=ceil(train_sample_num/ BATCH_SIZE),\n",
    "                    validation_steps=ceil(val_sample_num/ BATCH_SIZE),\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
