{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charged-opening",
   "metadata": {},
   "source": [
    "# <b><font color=\"#FF6633\">图像溯源-main</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-glossary",
   "metadata": {},
   "source": [
    "## 包导入与参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weekly-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载tensorflow模型\n",
    "import numpy as np\n",
    "import os\n",
    "# Uncomment the line below to make GPU unavaliable\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "from tensorflow.keras.layers import Dense,Dropout, Input, concatenate,Flatten\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-formula",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "1. 采用**vgg16**进行分类，使用在imageNet上进行预训练的模型进行迁移学习（当然我们的任务和和物体分类差别很大，所有预训练的模型在这里意义不是很大）  \n",
    "2. 池化选择**平均池化**：因为我们想要的是全局特征，平均池化有利于滤除细微的扰动【但我不确定max_pool是否会更好】   \n",
    "3. 优化方式为**sgd**,随机性更强的sgd更有利于跳过局部最优，对于我们的任务来说，当然是有必要的  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nearby-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义宏参数\n",
    "PICS_WIDTH,PICS_HEIGHT = 512,512\n",
    "MODEL_LOSS = 'categorical_crossentropy'\n",
    "MODEL_METRIC = 'categorical_accuracy'\n",
    "NUM_CATEGS = 10\n",
    "\n",
    "def InitialiazeModel(head_only,weights,model_name,lr=0.001):\n",
    "    \"\"\"\n",
    "    head_only:选择是否只训练顶端（即自定义的全连接层）\n",
    "    weights:选择是否从外部导入权重\n",
    "    model:模型名称\n",
    "    lr:学习率：默认为0.001\n",
    "    \"\"\"\n",
    "    if model_name == 'VGG19':\n",
    "        from tensorflow.keras.applications.vgg19 import VGG19\n",
    "        base_model = VGG19(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    # ================================ 该实验选择的分类器 ============================================ #\n",
    "    elif model_name == 'VGG16':\n",
    "        from tensorflow.keras.applications.vgg16 import VGG16\n",
    "        base_model = VGG16(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "        \n",
    "    # ============================================================================================== #\n",
    "    elif model_name == 'MobileNet':\n",
    "        from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "        base_model = MobileNet(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'ResNet50':\n",
    "        from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "        base_model = ResNet50(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'Xception':\n",
    "        from tensorflow.keras.applications.xception import Xception\n",
    "        base_model = Xception(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'InceptionV3':\n",
    "        from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "        base_model = InceptionV3(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'InceptionResNetV2':\n",
    "        from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "        base_model = InceptionResNetV2(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'NASNetLarge':\n",
    "        from tensorflow.keras.applications.nasnet import NASNetLarge\n",
    "        base_model = NASNetLarge(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    elif model_name == 'NASNetMobile':\n",
    "        from tensorflow.keras.applications.nasnet import NASNetMobile\n",
    "        base_model = NASNetMobile(include_top=False, weights='imagenet',\n",
    "                      input_shape=(PICS_WIDTH, PICS_HEIGHT, 3), pooling = 'avg')\n",
    "    else:\n",
    "        raise ValueError('Network name is undefined')\n",
    "    # 是否训练头部    \n",
    "    if head_only:\n",
    "        for lay in base_model.layers:\n",
    "            lay.trainable = False\n",
    "            \n",
    "    for i,lay in enumerate(base_model.layers):\n",
    "            # print(i,lay)\n",
    "            if i <= 14:\n",
    "                lay.trainable = False\n",
    "\n",
    "    # ======================= 全连接层 ======================================\n",
    "    flat1 = Flatten()(base_model.layers[-1].output)\n",
    "    # 第一层\n",
    "    class1 = Dense(256, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    dropout1 = Dropout(0.2)(class1)\n",
    "      # 第二层\n",
    "    class2 = Dense(128, activation='relu', kernel_initializer='he_uniform')(dropout1)\n",
    "    dropout2 = Dropout(0.2)(class2)\n",
    "    # 输出层\n",
    "    output = Dense(NUM_CATEGS, activation='softmax')(dropout2)\n",
    "    # define new model\n",
    "    model = Model(inputs=base_model.inputs, outputs=output)\n",
    "    \n",
    "    # print(model.summary())\n",
    "    # 如果存在已有权重则加载已有权重\n",
    "    if weights != '':\n",
    "        model.load_weights(weights)\n",
    "    # ========================= 优化器 =======================================\n",
    "#     MODEL_OPTIMIZER = optimizers.Adam(lr=0.001)\n",
    "    MODEL_OPTIMIZER = optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    # 编译模型\n",
    "    model.compile(loss=MODEL_LOSS, optimizer=MODEL_OPTIMIZER, metrics=[MODEL_METRIC])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "novel-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f35d34781d0>\n",
      "1 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d34633d0>\n",
      "2 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d347b390>\n",
      "3 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35d346b810>\n",
      "4 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d346b390>\n",
      "5 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35f85e1590>\n",
      "6 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35d3458a10>\n",
      "7 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d3423990>\n",
      "8 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d3437810>\n",
      "9 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d343d450>\n",
      "10 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35f70f1d50>\n",
      "11 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d3447490>\n",
      "12 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d344cf90>\n",
      "13 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d34548d0>\n",
      "14 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35d33e1fd0>\n",
      "15 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d33e6150>\n",
      "16 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d33ebb50>\n",
      "17 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d33f0850>\n",
      "18 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35d33f7c90>\n",
      "19 <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f35d33ffa90>\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,880,202\n",
      "Trainable params: 165,514\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f35c44b1990>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InitialiazeModel(head_only=True,weights='',model_name='VGG16',lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-enclosure",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "定义训练用变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technological-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "# 模型名\n",
    "model_name = \"VGG16\"\n",
    "train_path = \"./datasets/Train\"\n",
    "val_path = \"./datasets/Val_main\"\n",
    "BATCH_SIZE = 20\n",
    "train_sample_num = 9054\n",
    "val_sample_num = 1555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-treasure",
   "metadata": {},
   "source": [
    "导入数据  \n",
    "### 方法一：直接导入\n",
    "<b><font color=\"#F0000\" size=4>慎重,很占内存</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expressed-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(file_name):\n",
    "#     \"\"\"\n",
    "#     导入npz数据\n",
    "#     \"\"\"\n",
    "#     data = np.load(file_name)\n",
    "#     X, y = data['arr_0'], data['arr_1']\n",
    "#     return X,y\n",
    " \n",
    "    \n",
    "# # 导入训练集和验证集\n",
    "# train_X, train_y = load_data('datasets\\\\npz_file\\\\Train.npz')\n",
    "# val_X, val_y = load_data('datasets\\\\npz_file\\\\Val_main.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-grade",
   "metadata": {},
   "source": [
    "### 方法二：使用生成器\n",
    "生成类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dated-vacuum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple_iPhone6Plus', 'Canon_PowerShotA640', 'Sony_DSC-W170', 'Samsung_GalaxyS5', 'Huawei_P9', 'Nikon_D70s', 'OnePlus_A3003', 'Microsoft_Lumia640LTE', 'Lenovo_P70A', 'Xiaomi_RedmiNote3', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "category = os.listdir(\"./datasets/Train\")\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "little-equivalent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.ipynb_checkpoints'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(category))\n",
    "category.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chief-transcription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple_iPhone6Plus', 'Canon_PowerShotA640', 'Sony_DSC-W170', 'Samsung_GalaxyS5', 'Huawei_P9', 'Nikon_D70s', 'OnePlus_A3003', 'Microsoft_Lumia640LTE', 'Lenovo_P70A', 'Xiaomi_RedmiNote3']\n"
     ]
    }
   ],
   "source": [
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-scheduling",
   "metadata": {},
   "source": [
    "很麻烦的一件事是，初始的vgg16权重是在ImageNet上训练的，需要通过preprocess_input函数处理，而问题是keras的生成器函数ImageDataGenerator  \n",
    "没有提供能进行自定义预处理的接口。一个聪明的方法是**自定义一个生成器封装ImageDataGenerator，对ImageDataGenerator生成的图像进行处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norman-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_gen(directory,classes):\n",
    "    \"\"\"\n",
    "    生成器，对ImageDataGenerator的输出进行处理\n",
    "    \"\"\"\n",
    "    data_gen = ImageDataGenerator()\n",
    "    train_it = data_gen.flow_from_directory(directory=directory,target_size=(512,512),\n",
    "                                           classes=category,class_mode= \"categorical\",\n",
    "                                            batch_size=BATCH_SIZE)\n",
    "    while True:\n",
    "        X,y = next(train_it)\n",
    "        X = preprocess_input(X)\n",
    "        yield(X,y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-photograph",
   "metadata": {},
   "source": [
    "### 训练过程：\n",
    "初步想法是，每运行若干epoch，就停下，记录历史信息并绘图，从而决定是否继续训练下去  \n",
    "因而需要保存每次停止后的数据，并在下一次运行时导入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-duplicate",
   "metadata": {},
   "source": [
    "首先将底层冻结只训练顶层，这一步训练两个epoch即可  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "breathing-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-781384108c13>:23: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 30152 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.9234 - categorical_accuracy: 0.6969Found 1560 images belonging to 10 classes.\n",
      "453/453 [==============================] - 209s 461ms/step - loss: 0.9234 - categorical_accuracy: 0.6969 - val_loss: 1.1250 - val_categorical_accuracy: 0.6462\n",
      "Epoch 2/2\n",
      "453/453 [==============================] - 211s 467ms/step - loss: 0.7377 - categorical_accuracy: 0.7565 - val_loss: 1.0683 - val_categorical_accuracy: 0.6699\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from math import ceil\n",
    "# 仅训练顶层\n",
    "model = InitialiazeModel(head_only=True,weights='./model_weight/only_head201.hdf5',model_name = model_name, lr=0.004)\n",
    "# 定义callback(这里定义的callback比较简单，之后可以定义更加详细的callback)\n",
    "weights_path_name = \"./model_weight/only_head2{epoch:02d}.hdf5\" \n",
    "\n",
    "callbacks = [ModelCheckpoint(weights_path_name, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "            EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "            ReduceLROnPlateau(factor=0.2,\n",
    "                              patience=2, \n",
    "                              min_lr=0.001)]\n",
    "# 训练\n",
    "# history0 = model.fit(x=train_X,y=train_y,batch_size=TRAIN_BATCH_SIZE,epochs=2,validation_data=(val_X))\n",
    "history0 = model.fit_generator(generator = vgg16_gen(train_path,category),\n",
    "                    validation_data = vgg16_gen(val_path,category),\n",
    "                    epochs = 2,\n",
    "                    steps_per_epoch=ceil(train_sample_num/ BATCH_SIZE),\n",
    "                    validation_steps=ceil(val_sample_num/ BATCH_SIZE),\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-jewel",
   "metadata": {},
   "source": [
    "--- \n",
    "导入之前的模型，并在扩充的数据集上进行进一步训练（解冻底层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f35c44d8f10>\n",
      "1 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4490390>\n",
      "2 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4490a10>\n",
      "3 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35c448cf90>\n",
      "4 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35d34e6250>\n",
      "5 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c448e490>\n",
      "6 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35c445e790>\n",
      "7 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c446a390>\n",
      "8 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4470c50>\n",
      "9 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4476290>\n",
      "10 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35c4483dd0>\n",
      "11 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c44840d0>\n",
      "12 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4493910>\n",
      "13 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4492650>\n",
      "14 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35c4420d10>\n",
      "15 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4426d10>\n",
      "16 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4431610>\n",
      "17 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f35c4433710>\n",
      "18 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f35c4439a50>\n",
      "19 <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f35c443e9d0>\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,880,202\n",
      "Trainable params: 7,244,938\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From <ipython-input-13-7b4aada26f61>:26: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 30152 images belonging to 10 classes.\n",
      "Epoch 1/20\n",
      "   1/1250 [..............................] - ETA: 0s - loss: 1.1663 - categorical_accuracy: 0.5833WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.5593 - categorical_accuracy: 0.1020Found 1560 images belonging to 10 classes.\n",
      "1250/1250 [==============================] - 602s 481ms/step - loss: 2.5593 - categorical_accuracy: 0.1020 - val_loss: 2.3038 - val_categorical_accuracy: 0.1026\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 606s 485ms/step - loss: 2.3032 - categorical_accuracy: 0.0965 - val_loss: 2.3038 - val_categorical_accuracy: 0.0942\n",
      "Epoch 3/20\n",
      " 381/1250 [========>.....................] - ETA: 6:22 - loss: 2.3029 - categorical_accuracy: 0.0976"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau\n",
    "from math import ceil\n",
    "\n",
    "model_name = \"VGG16\"\n",
    "train_path = \"./datasets/Train\"\n",
    "val_path = \"./datasets/Val_main\"\n",
    "BATCH_SIZE = 24\n",
    "train_sample_num = 30000\n",
    "val_sample_num = 1555\n",
    "weights = './model_weight/only_head202.hdf5'\n",
    "# weights = ''\n",
    "\n",
    "model = InitialiazeModel(head_only=False,weights=weights,model_name = model_name, lr=0.001)\n",
    "weights_path_name = \"./model_weight/not_only_head{epoch:02d}.hdf5\" \n",
    "callbacks = [ModelCheckpoint(weights_path_name, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "             TensorBoard(log_dir='train_log',update_freq=20000)]\n",
    "history1 = model.fit_generator(generator = vgg16_gen(train_path,category),\n",
    "                    validation_data = vgg16_gen(val_path,category),\n",
    "                    epochs = 20,\n",
    "                    steps_per_epoch=ceil(train_sample_num/ BATCH_SIZE),\n",
    "                    validation_steps=ceil(val_sample_num/ BATCH_SIZE),\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-terrorism",
   "metadata": {},
   "source": [
    "以上**效果不佳**，，表现为一个epoch（30000）之后效果几乎没进步，因而我们试着只解冻若干卷积层，或者从头训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-quantity",
   "metadata": {},
   "source": [
    "--- \n",
    "从头开始（毕竟我们数据大）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prescribed-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-a46ce10b82c7>:30: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 30152 images belonging to 10 classes.\n",
      "Epoch 1/40\n",
      "   1/1250 [..............................] - ETA: 0s - loss: 0.0128 - categorical_accuracy: 1.0000WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0610 - categorical_accuracy: 0.9805Found 1560 images belonging to 10 classes.\n",
      "1250/1250 [==============================] - 616s 493ms/step - loss: 0.0610 - categorical_accuracy: 0.9805 - val_loss: 0.4883 - val_categorical_accuracy: 0.8833\n",
      "Epoch 2/40\n",
      "1250/1250 [==============================] - 608s 486ms/step - loss: 0.0440 - categorical_accuracy: 0.9857 - val_loss: 0.5064 - val_categorical_accuracy: 0.8814\n",
      "Epoch 3/40\n",
      "1250/1250 [==============================] - 627s 502ms/step - loss: 0.0325 - categorical_accuracy: 0.9894 - val_loss: 0.5669 - val_categorical_accuracy: 0.8801\n",
      "Epoch 4/40\n",
      " 138/1250 [==>...........................] - ETA: 8:35 - loss: 0.0211 - categorical_accuracy: 0.9945"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a46ce10b82c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                    \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                    verbose = 1)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau\n",
    "from math import ceil\n",
    "\n",
    "model_name = \"VGG16\"\n",
    "train_path = \"./datasets/Train\"\n",
    "val_path = \"./datasets/Val_main\"\n",
    "BATCH_SIZE = 24\n",
    "train_sample_num = 30000\n",
    "val_sample_num = 1555\n",
    "weights = './model_weight/sgd_not_only_head05.hdf5'\n",
    "# weights = ''\n",
    "\n",
    "model = InitialiazeModel(head_only=False,weights=weights,model_name = model_name, lr=0.001)\n",
    "\n",
    "weights_path_name = \"./model_weight/sgd_not_only_head{epoch:02d}.hdf5\" \n",
    "callbacks = [ModelCheckpoint(weights_path_name, monitor='val_loss', save_best_only=True, verbose=0,\n",
    "                                             save_weights_only=True),\n",
    "             EarlyStopping(monitor='val_loss', patience=3, verbose=0.01),\n",
    "             TensorBoard(log_dir='train_log',update_freq=20000),\n",
    "             ReduceLROnPlateau(factor=0.5,\n",
    "                               patience=1, \n",
    "                              min_lr=0.0005)]\n",
    "history1 = model.fit_generator(generator = vgg16_gen(train_path,category),\n",
    "                    validation_data = vgg16_gen(val_path,category),\n",
    "                    epochs = 40,\n",
    "                    steps_per_epoch=ceil(train_sample_num/ BATCH_SIZE),\n",
    "                    validation_steps=ceil(val_sample_num/ BATCH_SIZE),\n",
    "                   max_queue_size=20,\n",
    "                   callbacks=callbacks,\n",
    "                   verbose = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
